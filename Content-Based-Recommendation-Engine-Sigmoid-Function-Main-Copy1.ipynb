{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import request, jsonify\n",
    "from flask_cors import cross_origin\n",
    "from pymongo import MongoClient\n",
    "from bson import ObjectId\n",
    "from flask import Blueprint\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymongo import MongoClient, GEO2D\n",
    "from bson import ObjectId\n",
    "import os\n",
    "import dotenv\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from utils.models import unique\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import psycopg2\n",
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import sigmoid_kernel\n",
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recsys():\n",
    "# user info\n",
    "\n",
    "    user  =  '5fc76f2f4b1cab6b736b1019'\n",
    "    lat = 6.524379\n",
    "    long = 3.379206\n",
    "    \n",
    "    # impute user id and location\n",
    "    # userid =  '5fc76f2f4b1cab6b736b1019'\n",
    "    # lat = 6.524379\n",
    "    # long = 3.379206\n",
    "\n",
    "    # get the permission link\n",
    "    STAGING_URI = os.getenv(\"STAGING_URI\")\n",
    "    PROD_DB = os.getenv(\"PROD_DB\")\n",
    "    DEV_URI = os.getenv(\"MONGO_LINK\")\n",
    "\n",
    "\n",
    "    # initialize connection to MongoDB\n",
    "    try:\n",
    "        conn = MongoClient(PROD_DB)\n",
    "        db = conn['odadb']\n",
    "        print(db)\n",
    "    except Exception as p:\n",
    "\n",
    "        print('''jsonify({\"msgcode\": 4, \"status\": \"failed\", \"message\": \"Failed to Connect To Mongo Schema {}\".format(p)}), 401''')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Get orders\n",
    "    orders = pd.DataFrame((list(db.orders.aggregate([{\"$unwind\": \"$products\"}]))));\n",
    "    orders['products_id'] = orders['products'].apply(lambda x: x.get(\"productId\"))\n",
    "    orders['productName'] = orders['products'].apply(lambda x: x.get(\"productName\"))\n",
    "    orders['genericProductId'] = orders['products'].apply(lambda x: x.get(\"genericProductId\"))\n",
    "    orders['quantity'] = orders['products'].apply(lambda x: x.get(\"quantity\"))\n",
    "    orders['price'] = orders['products'].apply(lambda x: x.get(\"price\"))\n",
    "    orders['buyerId'] = orders['buyerId'].astype(str)\n",
    "    orders = orders[\n",
    "        ['buyerDropOffHandShake', 'buyerId', 'orderId', 'products_id', 'productName', 'genericProductId',\n",
    "         'quantity', 'price']]\n",
    "    orders['productName'] = orders['productName'].astype(str)\n",
    "    orders['buyerId'] = orders['buyerId'].astype(str)\n",
    "    # orders.dropna(subset=['productName'], how='all', inplace=True)\n",
    "    orders = orders.dropna(subset=['productName'])\n",
    "    orderss = orders.drop(['buyerDropOffHandShake'], axis=1)\n",
    "\n",
    "    userid = str(user)\n",
    "    useritems = orderss[orderss['buyerId'] == userid]\n",
    "    # Get Storeproducts\n",
    "    # storeproducts = list(db.storeproducts.find())\n",
    "    # storeproducts= pd.DataFrame(list(storeproducts))\n",
    "\n",
    "    storeproducts = db.storeproducts.find({\"status\": \"ACTIVE\", \"storeCoord\": {\n",
    "        \"$geoWithin\": {\"$centerSphere\": [[float(long), float(lat)], 4 / 6378.1]}}},\n",
    "                                          {'image': 1, 'genericProductId': 1, 'productName': 1,\n",
    "                                           'description': 1, 'storeCoord': 1})\n",
    "    storeproducts = pd.DataFrame(list(storeproducts))\n",
    "\n",
    "    # Get  genericproducts\n",
    "    genericproducts = list(db.genericproducts.find())\n",
    "    genericproducts = pd.DataFrame(list(genericproducts))\n",
    "\n",
    "    if len(storeproducts) < 1:\n",
    "\n",
    "        print('''return jsonify(\n",
    "            {\"msgcode\": 6, \"status\": \"success\", \"message\": \" No related product found nearby\", \"data\": []}), 200''')\n",
    "    elif len(useritems) < 1:\n",
    "\n",
    "        print('''return jsonify({\"msgcode\": 6, \"status\": \"success\", \"message\": \" No order history of customer found\",\n",
    "                        \"data\": []}), 200''')\n",
    "\n",
    "    # selected generic product columns is named as data for training\n",
    "    data = genericproducts[\n",
    "        ['subcategoryName', 'productName', 'description', 'categoryName', 'comment', 'image']]\n",
    "\n",
    "    # preprocess data(genericproducts)\n",
    "    data['subcategoryName'] = data['subcategoryName'].astype(str)\n",
    "    data['productName'] = data['productName'].astype(str)\n",
    "    data['description'] = data['description'].astype(str)\n",
    "    data['subcategoryName'] = data['subcategoryName'].str.strip('[')\n",
    "    data['subcategoryName'] = data['subcategoryName'].str.strip(']')\n",
    "\n",
    "    # data = data.drop_duplicates()\n",
    "    data.dropna(subset=['productName', 'description'], how='all', inplace=True)\n",
    "    data = data.reset_index()\n",
    "\n",
    "    # preprocess storeproducts and get needed columns\n",
    "    storeproducts.columns\n",
    "    storeproducts = storeproducts[['storeCoord', 'image', 'productName', 'description', 'genericProductId']]\n",
    "\n",
    "    print(\"orders.shape :\", orders.shape)\n",
    "    print(\"storeproducts :\", storeproducts.shape)\n",
    "    print(\"genericproducts :\", data.shape)\n",
    "\n",
    "    # vectorize data description columns\n",
    "\n",
    "    tfv = TfidfVectorizer(min_df=3, max_features=None,\n",
    "                          strip_accents='unicode', analyzer='word', token_pattern=r'\\w{1,}',\n",
    "                          ngram_range=(1, 3),\n",
    "                          stop_words='english')\n",
    "\n",
    "    tfv_matrix = tfv.fit_transform(data['description'])\n",
    "\n",
    "    # tfv_matrix.shape\n",
    "\n",
    "    # Compute the sigmoid kernel to get correlations amongs items\n",
    "    sig = sigmoid_kernel(tfv_matrix, tfv_matrix)\n",
    "\n",
    "    # Reverse mapping of indices and productName\n",
    "    indices = pd.Series(data.index, index=data['productName'])\n",
    "\n",
    "    def give_rec(items, sig=sig):\n",
    "        # Get the index corresponding to productName\n",
    "        idx = indices[items]\n",
    "\n",
    "        # Get the pairwsie similarity scores\n",
    "        sig_scores = list(enumerate(sig[idx]))\n",
    "\n",
    "        # Sort the items\n",
    "        sig_scores = sorted(sig_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Scores of the 500 most similar items\n",
    "        sig_scores = sig_scores[1:500]\n",
    "\n",
    "        # item indices\n",
    "        m_indices = [i[0] for i in sig_scores]\n",
    "\n",
    "        # Top most similar items\n",
    "        return data['productName'].iloc[m_indices]\n",
    "\n",
    "    storeproducts.columns\n",
    "\n",
    "    # impute user id and location\n",
    "    # userid =  '5fc76f2f4b1cab6b736b1019'\n",
    "    # lat = 6.524379\n",
    "    # long = 3.379206\n",
    "\n",
    "    # remove duplicates\n",
    "    orderss.drop_duplicates(keep=False, inplace=True)\n",
    "\n",
    "    # get the a random product name of one of identified customer's orders\n",
    "\n",
    "    # give recommendation based on past buys\n",
    "\n",
    "    one_product = orderss[orderss['buyerId'] == user].productName.sample().values[0]\n",
    "    print(one_product)\n",
    "    \n",
    "    if one_product is None  or  one_product == None :\n",
    "        print('''return  jsonify({\"msgcode\": 5, \"status\": \"failed\", \"message\": \"No recommendation\"}), 400''')\n",
    "    \n",
    "    else :\n",
    "\n",
    "        recomm = give_rec(one_product)\n",
    "\n",
    "        # merging recommended items with storeproducts filtered by nearest locations\n",
    "        recomm = pd.DataFrame(recomm, columns=['productName'])\n",
    "        storeproducts1 = storeproducts[['image', 'productName', 'description', 'genericProductId']]\n",
    "        storeproducts1['productName'] = storeproducts1['productName'].astype(str)\n",
    "        recomm_final = recomm.merge(storeproducts1, how='inner', on='productName')\n",
    "\n",
    "        final = pd.DataFrame()\n",
    "        final[['image', 'productName', 'uid']] = recomm_final[['image', 'productName', 'genericProductId']]\n",
    "        final = final.to_dict(orient='records')\n",
    "        final = unique(final)\n",
    "\n",
    "\n",
    "        print(final)\n",
    "\n",
    "        print('''return jsonify({\"msgcode\": 8, \"status\": \"success\", \"data\": final}), 200''')\n",
    "\n",
    "\n",
    "\n",
    "        print('''return jsonify({\"msgcode\": 10, \"status\": \"success\", \"message\": 'Something went Wrong'}), 500''')\n",
    "\n",
    "    print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
